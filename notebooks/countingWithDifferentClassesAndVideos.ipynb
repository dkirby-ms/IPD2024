{
 "cells": [
  {
   "cell_type": "raw",
   "id": "36548180",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "%pip install opencv-python pyyaml openvino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f165089-ff60-415f-8a21-56ac818b20c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openvino\n",
    "%pip install \"ultralytics==8.2.24\"\n",
    "import platform\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "# Inference function\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.solutions import ObjectCounter\n",
    "import cv2\n",
    "import time\n",
    "import collections\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "import torch\n",
    "import openvino as ov\n",
    "#import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbbf1c7-af96-40fd-96e1-04fc648811fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models_dir = Path(\"./models\")\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "DET_MODEL_NAME = \"yolov8n\"\n",
    "\n",
    "det_model = YOLO(models_dir / f\"{DET_MODEL_NAME}.pt\")\n",
    "label_map = det_model.model.names\n",
    "\n",
    "# Need to make en empty call to initialize the model\n",
    "res = det_model()\n",
    "det_model_path = models_dir / f\"{DET_MODEL_NAME}_openvino_model/{DET_MODEL_NAME}.xml\"\n",
    "if not det_model_path.exists():\n",
    "    det_model.export(format=\"openvino\", dynamic=True, half=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1a460c-3d62-464a-ba56-ac218531e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor=\"green\", facecolor=(0, 0, 0, 0), lw=2))\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels == 1]\n",
    "    neg_points = coords[labels == 0]\n",
    "    ax.scatter(\n",
    "        pos_points[:, 0],\n",
    "        pos_points[:, 1],\n",
    "        color=\"green\",\n",
    "        marker=\"*\",\n",
    "        s=marker_size,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.25,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        neg_points[:, 0],\n",
    "        neg_points[:, 1],\n",
    "        color=\"red\",\n",
    "        marker=\"*\",\n",
    "        s=marker_size,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.25,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755fa832-ac41-4abf-8124-54d2ae4efd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"ultralytics==8.2.24\" opencv-python pyyaml openvino\n",
    "def run_inference(source, deviceType, objectToCount):\n",
    "    core = ov.Core()\n",
    "   \n",
    "    det_ov_model = core.read_model(det_model_path)\n",
    "    ov_config = {}\n",
    "\n",
    "    compiled_model = core.compile_model(det_ov_model, deviceType, ov_config)\n",
    "\n",
    "    def infer(*args):\n",
    "        result = compiled_model(args)\n",
    "        return torch.from_numpy(result[0])\n",
    "\n",
    "    # Use openVINO as inference engine\n",
    "    det_model.predictor.inference = infer\n",
    "    det_model.predictor.model.pt = False\n",
    "\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(source)\n",
    "        assert cap.isOpened(), \"Error reading video file\"\n",
    "        # line_points = [(0, 300), (1080, 300)]  \n",
    "        # line_points = [(0, 1080, 1080, 0, 0), (300, 300,0,0, 300)]  # line or region points\n",
    "        line_points = [(0, 300), (500, 300),(500, 0),(0,0),(0,300)]  # line or region points\n",
    "\n",
    "        classes_to_count = [0]  # person is class 0 in the COCO dataset, 46 is banana and 47 is apples.\n",
    "        if(objectToCount == \"person\"):\n",
    "            classes_to_count == [0]\n",
    "        if(objectToCount == \"banana\"):\n",
    "            classes_to_count = [46]\n",
    "        if(objectToCount == \"apple\"):\n",
    "           classes_to_count = [47]\n",
    "\n",
    "           \n",
    "        # Init Object Counter\n",
    "        counter = ObjectCounter(\n",
    "            view_img=False, reg_pts=line_points, classes_names=det_model.names, draw_tracks=True, line_thickness=1, view_in_counts=False, view_out_counts=False\n",
    "        )\n",
    "        # Processing time\n",
    "        processing_times = collections.deque(maxlen=200)\n",
    "\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "                break\n",
    "\n",
    "            start_time = time.time()\n",
    "            tracks = det_model.track(frame, persist=True, show=False, classes=classes_to_count, verbose=False)\n",
    "            frame = counter.start_counting(frame, tracks)\n",
    "            stop_time = time.time()\n",
    "\n",
    "            processing_times.append(stop_time - start_time)\n",
    "\n",
    "            # Mean processing time [ms].\n",
    "            _, f_width = frame.shape[:2]\n",
    "            processing_time = np.mean(processing_times) * 1000\n",
    "            fps = 1000 / processing_time\n",
    "            cv2.putText(\n",
    "                img=frame,\n",
    "                text=f\"Inference time: {processing_time:.1f}ms ({fps:.1f} FPS)\",\n",
    "                org=(20, 40),\n",
    "                fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "                fontScale=f_width / 1000,\n",
    "                color=(0, 0, 255),\n",
    "                thickness=2,\n",
    "                lineType=cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "            # Get the counts. Counts are getting as 'OUT'\n",
    "            # Modify this logic accordingly\n",
    "            counts = counter.out_counts\n",
    "\n",
    "            # Define the text to display\n",
    "            text = f\"Count: {counts}\"\n",
    "            fontFace = cv2.FONT_HERSHEY_COMPLEX\n",
    "            fontScale = 0.75  # Adjust scale as needed\n",
    "            thickness = 2\n",
    "\n",
    "            # Calculate the size of the text box\n",
    "            (text_width, text_height), _ = cv2.getTextSize(text, fontFace, fontScale, thickness)\n",
    "\n",
    "            # Define the upper right corner for the text\n",
    "            top_right_corner = (frame.shape[1] - text_width - 20, 40)\n",
    "            # Draw the count of \"OUT\" on the frame\n",
    "            cv2.putText(\n",
    "                img=frame,\n",
    "                text=text,\n",
    "                org=(top_right_corner[0], top_right_corner[1]),\n",
    "                fontFace=fontFace,\n",
    "                fontScale=fontScale,\n",
    "                color=(0, 0, 255),\n",
    "                thickness=thickness,\n",
    "                lineType=cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "            # Show the frame\n",
    "            _, encoded_img = cv2.imencode(ext=\".jpg\", img=frame, params=[cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "            # Create an IPython image.\n",
    "            i = display.Image(data=encoded_img)\n",
    "            # Display the image in this notebook.          \n",
    "            display.clear_output(wait=True)\n",
    "            display.display(i)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6455fb8b-384c-4d1e-b227-88e499b66c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_SOURCE = \"https://dm0qx8t0i9gc9.cloudfront.net/watermarks/video/49_20HQOeijh9fog1/uae-dubai-february-1-2016-people-near-shop-counter-with-fresh-fruits-inside-dubai-mall-in-united-arab-emirates-dubai-mall-is-the-world-largest-shopping-mall_nixdioorg__54efbe10ef1db686a89eb84a13815e70__P360.mp4\"\n",
    "\n",
    "core = ov.Core()\n",
    "deviceType = \"CPU\"\n",
    "\n",
    "run_inference(\n",
    "    source=VIDEO_SOURCE,\n",
    "    deviceType=deviceType,\n",
    "    objectToCount=\"apple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933dc67f-e7b5-496c-850f-9929e0906115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00c31ed-4c40-4834-92b7-bcf359f0dd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bbb108-5e55-4c84-b1ec-7c8a1fd8a727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
