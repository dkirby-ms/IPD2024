{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67aa4381",
   "metadata": {},
   "source": [
    "## Counting objects with YOLO8\n",
    "\n",
    "In this exercise, we will count a particular object in real-time using [YOLOv8](https://docs.ultralytics.com/models/yolov8/) object detection model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54378033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q opencv-python pyyaml ultralytics paho-mqtt opencv_jupyter_ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cbbf1c7-af96-40fd-96e1-04fc648811fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ 'source' is missing. Using 'source=/home/saitcho/IPD2024/.venv/lib/python3.12/site-packages/ultralytics/assets'.\n",
      "\n",
      "image 1/2 /home/saitcho/IPD2024/.venv/lib/python3.12/site-packages/ultralytics/assets/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 80.4ms\n",
      "image 2/2 /home/saitcho/IPD2024/.venv/lib/python3.12/site-packages/ultralytics/assets/zidane.jpg: 384x640 2 persons, 1 tie, 10.3ms\n",
      "Speed: 4.0ms preprocess, 45.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import platform, cv2, time, collections, torch, yaml, json\n",
    "import opencv_jupyter_ui as jcv2\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "# Define the model to be used.\n",
    "det_model = YOLO('yolov8n.pt')  # You can use 'yolov8s.pt', 'yolov8m.pt', etc. for different model sizes\n",
    "    \n",
    "# Loading the model names.\n",
    "label_map = det_model.model.names\n",
    "reversed_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# Need to make en empty call to initialize the model\n",
    "res = det_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2281289",
   "metadata": {},
   "source": [
    "### Detect and count objects\n",
    "Configure your choice of video and object to count by adjusting the variables below.\n",
    "\n",
    "Possible object types can be found by reviewing [coco.yaml](../artifacts/coco.yaml)\n",
    "\n",
    "Number of counted objects will be written to a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16240b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample videos: \n",
    "#\n",
    "# https://download.microsoft.com/download/caaf80b6-2394-4fbc-8430-8b41a3206c64/people-are-pushing-carts-along.mp4\n",
    "# https://download.microsoft.com/download/a0ac5d61-60b6-4037-9555-ba5acefeb0c8/people-near-shop-counter-fruit.mp4\n",
    "sourceVideo = \"https://download.microsoft.com/download/caaf80b6-2394-4fbc-8430-8b41a3206c64/people-are-pushing-carts-along.mp4\"\n",
    "objectToCount = \"person\" # You can change this to any object in the model - backpack, handbag, suitcase, apple, orange, giraffe\n",
    "\n",
    "# Initialize a dictionary to store the counts\n",
    "object_counts = {}\n",
    "\n",
    "# Modify the run_inference function to update the object_counts dictionary\n",
    "def run_inference(source, deviceType, objectToCount):\n",
    "    objectid = reversed_label_map[objectToCount]\n",
    "    frame_count = 0\n",
    "    cap = cv2.VideoCapture(source)\n",
    "    assert cap.isOpened(), \"Error reading video file\"\n",
    "    \n",
    "    line_points = [(0, 600), (800, 600),(800, 0),(0,0),(0,600)]  # line or region points\n",
    "\n",
    "    # open the video feed\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        object_count = 0\n",
    "        if not success:\n",
    "            print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "            break\n",
    "        # Count persons in the current frame\n",
    "        results = det_model(frame)\n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                if box.cls[0] == objectid:\n",
    "                    object_count += 1\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f'{objectToCount}', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "         \n",
    "        # Update the object_counts dictionary\n",
    "        object_counts[frame_count] = object_count\n",
    "        frame_count += 1\n",
    "\n",
    "        # Display the frame with the count\n",
    "        cv2.putText(frame, f'{label_map[objectid]}: {object_count}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        jcv2.imshow('Frame', frame)\n",
    "        \n",
    "        if jcv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    jcv2.destroyAllWindows()\n",
    "\n",
    "    # Write the object_counts dictionary to a JSON file\n",
    "    with open('object_counts.json', 'w') as f:\n",
    "        json.dump(object_counts, f)\n",
    "\n",
    "# Run the inference\n",
    "run_inference(\n",
    "    source=sourceVideo,\n",
    "    deviceType=\"GPU\",\n",
    "    objectToCount=objectToCount\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0ad7e0",
   "metadata": {},
   "source": [
    "### Plot some data\n",
    "Now we can plot the [data](./object_counts.json) captured by our app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b827c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the object counts data\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(list(object_counts.keys()), list(object_counts.values()), marker='o')\n",
    "plt.title(f'Count of {objectToCount} in each frame')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66279c",
   "metadata": {},
   "source": [
    "### Send to MQTT\n",
    "By capturing data as json messages we can send them to an MQTT broker. These messages can then be used as triggers or inputs for other types of actions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e775268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paho.mqtt.client as mqtt\n",
    "\n",
    "# Define the MQTT broker details\n",
    "broker = \"test.mosquitto.org\"\n",
    "port = 1883\n",
    "topic = \"Ignite2024/Labs/ObjectCounts\"\n",
    "\n",
    "# Create an MQTT client instance\n",
    "client = mqtt.Client()\n",
    "\n",
    "# Connect to the broker\n",
    "client.connect(broker, port, 60)\n",
    "\n",
    "# Publish the object counts to the MQTT broker\n",
    "for frame, count in object_counts.items():\n",
    "    payload = json.dumps({\"frame\": frame, \"count\": count})\n",
    "    client.publish(topic, payload)\n",
    "    print(f\"Published: {payload}\")\n",
    "\n",
    "# Disconnect from the broker\n",
    "client.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e20330",
   "metadata": {},
   "source": [
    "## Complete Lab\n",
    "Run the following cell to complete this lab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4437f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r userId\n",
    "import requests;print(requests.post(\"https://jsleaderboard001-cnece0effvapgbft.westus2-01.azurewebsites.net/complete_task\", headers={\"Content-Type\": \"application/json\"}, json={\"user_id\": userId, \"task_id\": 3}).json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1839734",
   "metadata": {},
   "source": [
    "### Continue\n",
    "\n",
    "[Notebook 4 - Meter reader](./4-Meter-Reader.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
