{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67aa4381",
   "metadata": {},
   "source": [
    "## Counting objects with YOLO8\n",
    "\n",
    "In this exercise, we will count a particular object in real-time using [YOLOv8](https://docs.ultralytics.com/models/yolov8/) object detection model. We will see how we can effectivily monitor not only static objects but also the objects as they move within a bounding box. We will also see how we can change the object that we want to count for different scenarios. Run the next cell to initialize the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54378033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q opencv-python pyyaml ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f654383d",
   "metadata": {},
   "source": [
    "### Initializing the model\n",
    "\n",
    "Our next step is to initialize the model. Key points about this steps are :\n",
    "- Detection model name is declared. In our case that is \"yolov8n\"\n",
    "- Detection model path is set.\n",
    "- Label map is loaded. The label map tells us what class of objects we can use to accomplish the counting of a particular object. For example, we can use people as class of object, or apples. Label map is the list of all those classes of objects.\n",
    "\n",
    "Click on the Play icon to the left of the cell below to initialize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cbbf1c7-af96-40fd-96e1-04fc648811fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ 'source' is missing. Using 'source=/home/dakir/IPD2024/.venv/lib/python3.12/site-packages/ultralytics/assets'.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dakir/IPD2024/.venv/lib/python3.12/site-packages/ultralytics/nn/tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/2 /home/dakir/IPD2024/.venv/lib/python3.12/site-packages/ultralytics/assets/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 84.3ms\n",
      "image 2/2 /home/dakir/IPD2024/.venv/lib/python3.12/site-packages/ultralytics/assets/zidane.jpg: 384x640 2 persons, 1 tie, 61.9ms\n",
      "Speed: 4.3ms preprocess, 73.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import platform, cv2, time, collections, torch, yaml\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the model to be used.\n",
    "det_model = YOLO('yolov8n.pt')  # You can use 'yolov8s.pt', 'yolov8m.pt', etc. for different model sizes\n",
    "    \n",
    "# Loading the model names.\n",
    "label_map = det_model.model.names\n",
    "reversed_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# Need to make en empty call to initialize the model\n",
    "res = det_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936dfbe8",
   "metadata": {},
   "source": [
    "### Define helper functions\n",
    "These helper functions draw the box around the detected object, and track the detected object.\n",
    "\n",
    "Click on the Play icon to the left of the cell below to setup the helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c1a460c-3d62-464a-ba56-ac218531e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor=\"green\", facecolor=(0, 0, 0, 0), lw=2))\n",
    "\n",
    "# Function defined to draw points. \n",
    "# This is function creates points with colors and other details.\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels == 1]\n",
    "    neg_points = coords[labels == 0]\n",
    "    ax.scatter(\n",
    "        pos_points[:, 0],\n",
    "        pos_points[:, 1],\n",
    "        color=\"green\",\n",
    "        marker=\"*\",\n",
    "        s=marker_size,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.25,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        neg_points[:, 0],\n",
    "        neg_points[:, 1],\n",
    "        color=\"red\",\n",
    "        marker=\"*\",\n",
    "        s=marker_size,\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=1.25,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c12345",
   "metadata": {},
   "source": [
    "### Inferencing function\n",
    "The inferencing function is the core of the this excercise. This function takes three parameters. These paramters are:\n",
    "- Source: This parameter tells the inferencing function which video feed to use as the source.\n",
    "- DeviceType: This parameter is related to the device type to use for inferencing. In our example, we are going to use \"CPU\" as the devices type. Other example of this parater is \"GPU\" which we are not using in this exercise.\n",
    "- Object to count - This parameter tells what object to use for counting. \n",
    "\n",
    "\n",
    "Click on the Play icon to the left of the cell below to setup the inferencing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "755fa832-ac41-4abf-8124-54d2ae4efd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion defined to run the inferencing using source video and target object.\n",
    "def run_inference(source, deviceType, objectToCount):\n",
    "    objectid = reversed_label_map[objectToCount]\n",
    "    frame_count = 0\n",
    "    cap = cv2.VideoCapture(source)\n",
    "    assert cap.isOpened(), \"Error reading video file\"\n",
    "    \n",
    "    line_points = [(0, 600), (800, 600),(800, 0),(0,0),(0,600)]  # line or region points\n",
    "\n",
    "    # open the video feed\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        object_count = 0\n",
    "        if not success:\n",
    "            print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "            break\n",
    "        # Count persons in the current frame\n",
    "        results = det_model(frame)\n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                if box.cls[0] == objectid:\n",
    "                    object_count += 1\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, f'{objectToCount}', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "         \n",
    "        # Display the frame with the count\n",
    "        cv2.putText(frame, f'{label_map[objectid]}: {object_count}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b624fba",
   "metadata": {},
   "source": [
    "### Configure video and choose what to track\n",
    "For this step, assign one of three values to objectToCount variable below. The three options are: person, apple and banana.\n",
    "\n",
    "- To accomplish this, enter the value for \"objectToCount\" variable in the below cell.\n",
    "- Once \"objectToCount\" variable is set, click on the play icon to the left of the cell below to execute assigning of the source vide step\n",
    "\n",
    "Additionally, provide a URL of a Video feed that would be used as the source video for inference.\n",
    "\n",
    "- To accomplish this, enter the value for \"sourceVideo\" variable in the below cell.\n",
    "- Once \"sourceVideo\" variable is set, click on the play icon to the left of the cell below to execute assigning of the source vide step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16240b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectToCount = \"boat\"   # \"person\", \"apple\" or \"banana\"\n",
    "\n",
    "# Available video 1: https://download.microsoft.com/download/caaf80b6-2394-4fbc-8430-8b41a3206c64/people-are-pushing-carts-along.mp4\n",
    "# Available video 2: https://download.microsoft.com/download/a0ac5d61-60b6-4037-9555-ba5acefeb0c8/people-near-shop-counter-fruit.mp4\n",
    "sourceVideo = \"https://download.microsoft.com/download/caaf80b6-2394-4fbc-8430-8b41a3206c64/people-are-pushing-carts-along.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3680b2",
   "metadata": {},
   "source": [
    "### Execution\n",
    "This is the final step of the exercise. In this step, the inferening function that was defined in the previous step, is called and the output result is shown.\n",
    "As mentioned previously, the inferencing function receives the information about the source of the video, the deviceType (in our case it is \"CPU\") and the object to count information from this execution step.\n",
    "\n",
    "Click on the Play icon to the left of the cell below to execute the final step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6455fb8b-384c-4d1e-b227-88e499b66c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 6 persons, 64.1ms\n",
      "Speed: 4.7ms preprocess, 64.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 boat, 63.9ms\n",
      "Speed: 4.8ms preprocess, 63.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 boat, 61.0ms\n",
      "Speed: 4.4ms preprocess, 61.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 60.8ms\n",
      "Speed: 4.4ms preprocess, 60.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 60.9ms\n",
      "Speed: 4.2ms preprocess, 60.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 apple, 6.4ms\n",
      "Speed: 1.3ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 apples, 6.0ms\n",
      "Speed: 2.6ms preprocess, 6.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 apples, 5.0ms\n",
      "Speed: 1.6ms preprocess, 5.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 5.1ms\n",
      "Speed: 1.7ms preprocess, 5.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 apples, 4.9ms\n",
      "Speed: 1.4ms preprocess, 4.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 apple, 5.0ms\n",
      "Speed: 1.4ms preprocess, 5.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 apple, 5.1ms\n",
      "Speed: 1.6ms preprocess, 5.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 apple, 5.6ms\n",
      "Speed: 1.9ms preprocess, 5.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4.8ms\n",
      "Speed: 1.6ms preprocess, 4.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 5.0ms\n",
      "Speed: 1.5ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 5.4ms\n",
      "Speed: 1.5ms preprocess, 5.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 motorcycle, 11.5ms\n",
      "Speed: 1.5ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 backpacks, 1 apple, 11.5ms\n",
      "Speed: 2.0ms preprocess, 11.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 backpacks, 2 apples, 5.1ms\n",
      "Speed: 1.3ms preprocess, 5.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 backpacks, 1 apple, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 motorcycle, 3 backpacks, 8.9ms\n",
      "Speed: 1.8ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 truck, 1 boat, 1 backpack, 5.4ms\n",
      "Speed: 1.3ms preprocess, 5.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 boat, 1 backpack, 1 skateboard, 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 truck, 1 backpack, 2 skateboards, 5.8ms\n",
      "Speed: 1.9ms preprocess, 5.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 truck, 1 backpack, 1 skateboard, 5.1ms\n",
      "Speed: 1.4ms preprocess, 5.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 backpacks, 6.7ms\n",
      "Speed: 1.5ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 backpacks, 1 snowboard, 6.4ms\n",
      "Speed: 1.4ms preprocess, 6.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 backpacks, 1 snowboard, 7.2ms\n",
      "Speed: 1.6ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 backpacks, 6.1ms\n",
      "Speed: 2.3ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 backpacks, 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 backpacks, 5.0ms\n",
      "Speed: 1.6ms preprocess, 5.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 backpacks, 5.2ms\n",
      "Speed: 1.5ms preprocess, 5.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 backpacks, 5.3ms\n",
      "Speed: 1.4ms preprocess, 5.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 backpack, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 truck, 2 backpacks, 5.5ms\n",
      "Speed: 1.8ms preprocess, 5.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 truck, 1 backpack, 5.5ms\n",
      "Speed: 1.6ms preprocess, 5.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 backpack, 7.2ms\n",
      "Speed: 2.7ms preprocess, 7.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 truck, 1 backpack, 6.5ms\n",
      "Speed: 1.5ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 truck, 2 backpacks, 5.0ms\n",
      "Speed: 1.5ms preprocess, 5.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 truck, 1 backpack, 5.9ms\n",
      "Speed: 1.7ms preprocess, 5.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 truck, 2 backpacks, 5.7ms\n",
      "Speed: 1.9ms preprocess, 5.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 truck, 2 backpacks, 1 skateboard, 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 truck, 2 backpacks, 1 skateboard, 7.2ms\n",
      "Speed: 1.5ms preprocess, 7.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 backpack, 5.7ms\n",
      "Speed: 2.1ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 truck, 2 backpacks, 1 skateboard, 6.2ms\n",
      "Speed: 1.7ms preprocess, 6.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 truck, 1 backpack, 1 skateboard, 5.2ms\n",
      "Speed: 1.6ms preprocess, 5.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 backpacks, 2 skateboards, 5.2ms\n",
      "Speed: 1.4ms preprocess, 5.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 backpacks, 2 skateboards, 5.2ms\n",
      "Speed: 1.6ms preprocess, 5.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 backpacks, 1 skateboard, 5.1ms\n",
      "Speed: 1.5ms preprocess, 5.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 backpacks, 5.0ms\n",
      "Speed: 1.5ms preprocess, 5.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 backpacks, 5.2ms\n",
      "Speed: 1.6ms preprocess, 5.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 backpacks, 9.0ms\n",
      "Speed: 1.8ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 6.0ms\n",
      "Speed: 2.2ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 backpacks, 5.2ms\n",
      "Speed: 1.4ms preprocess, 5.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 backpacks, 1 skateboard, 6.0ms\n",
      "Speed: 1.4ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 backpacks, 1 skateboard, 4.9ms\n",
      "Speed: 1.4ms preprocess, 4.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 backpacks, 7.8ms\n",
      "Speed: 1.5ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 truck, 1 backpack, 1 handbag, 6.6ms\n",
      "Speed: 1.5ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 truck, 2 backpacks, 1 handbag, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 truck, 2 backpacks, 1 handbag, 1 skateboard, 6.5ms\n",
      "Speed: 1.3ms preprocess, 6.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 truck, 1 backpack, 1 handbag, 1 skateboard, 7.3ms\n",
      "Speed: 1.5ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 1 handbag, 1 skateboard, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 truck, 1 backpack, 1 handbag, 1 skateboard, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 truck, 1 backpack, 1 handbag, 2 skateboards, 5.2ms\n",
      "Speed: 1.5ms preprocess, 5.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 truck, 2 backpacks, 1 handbag, 1 skateboard, 5.4ms\n",
      "Speed: 1.6ms preprocess, 5.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 truck, 2 backpacks, 1 handbag, 1 skateboard, 8.2ms\n",
      "Speed: 1.4ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 truck, 2 backpacks, 1 skateboard, 6.3ms\n",
      "Speed: 1.3ms preprocess, 6.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 truck, 2 backpacks, 1 skateboard, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 backpack, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 backpack, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 backpack, 6.3ms\n",
      "Speed: 1.3ms preprocess, 6.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 backpacks, 8.0ms\n",
      "Speed: 1.8ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 backpacks, 5.5ms\n",
      "Speed: 1.7ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 backpacks, 5.7ms\n",
      "Speed: 1.8ms preprocess, 5.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 backpacks, 1 handbag, 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 backpacks, 6.8ms\n",
      "Speed: 2.1ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 backpacks, 5.5ms\n",
      "Speed: 1.4ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 backpacks, 6.3ms\n",
      "Speed: 1.5ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 motorcycle, 2 backpacks, 5.8ms\n",
      "Speed: 1.6ms preprocess, 5.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 backpacks, 5.1ms\n",
      "Speed: 1.6ms preprocess, 5.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 backpack, 4.7ms\n",
      "Speed: 1.3ms preprocess, 4.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 backpack, 5.0ms\n",
      "Speed: 1.3ms preprocess, 5.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 backpacks, 6.6ms\n",
      "Speed: 1.5ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 backpack, 6.0ms\n",
      "Speed: 2.2ms preprocess, 6.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 backpack, 8.6ms\n",
      "Speed: 1.4ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 backpack, 7.1ms\n",
      "Speed: 1.9ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 truck, 1 backpack, 6.9ms\n",
      "Speed: 2.4ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 truck, 6.3ms\n",
      "Speed: 1.3ms preprocess, 6.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 6.2ms\n",
      "Speed: 1.3ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 backpack, 6.3ms\n",
      "Speed: 1.3ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 boats, 1 backpack, 6.4ms\n",
      "Speed: 1.5ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 boats, 6.5ms\n",
      "Speed: 1.5ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 boats, 6.7ms\n",
      "Speed: 1.4ms preprocess, 6.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 boat, 7.2ms\n",
      "Speed: 1.5ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 10.2ms\n",
      "Speed: 1.8ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 backpack, 6.8ms\n",
      "Speed: 1.4ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 boat, 6.6ms\n",
      "Speed: 2.0ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 9.8ms\n",
      "Speed: 1.8ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 6.3ms\n",
      "Speed: 1.4ms preprocess, 6.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 6.3ms\n",
      "Speed: 1.3ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 boat, 1 backpack, 6.7ms\n",
      "Speed: 1.3ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 boat, 7.6ms\n",
      "Speed: 1.4ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 boat, 6.8ms\n",
      "Speed: 1.8ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 boats, 1 backpack, 7.3ms\n",
      "Speed: 1.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 boats, 1 backpack, 11.0ms\n",
      "Speed: 1.3ms preprocess, 11.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 boat, 1 backpack, 11.2ms\n",
      "Speed: 1.4ms preprocess, 11.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 backpack, 15.1ms\n",
      "Speed: 1.3ms preprocess, 15.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 boat, 1 backpack, 8.4ms\n",
      "Speed: 2.6ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 boat, 1 backpack, 6.8ms\n",
      "Speed: 1.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 boat, 1 backpack, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 boat, 1 backpack, 6.9ms\n",
      "Speed: 1.4ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 backpacks, 1 handbag, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 boat, 2 backpacks, 1 handbag, 6.6ms\n",
      "Speed: 1.4ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 boat, 2 backpacks, 1 handbag, 6.6ms\n",
      "Speed: 1.3ms preprocess, 6.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 boat, 3 backpacks, 1 handbag, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 backpacks, 7.1ms\n",
      "Speed: 1.6ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 backpacks, 6.5ms\n",
      "Speed: 1.4ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 backpacks, 6.6ms\n",
      "Speed: 1.5ms preprocess, 6.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 backpacks, 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 backpacks, 6.6ms\n",
      "Speed: 2.1ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 backpacks, 1 handbag, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 6.7ms\n",
      "Speed: 1.5ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 backpacks, 6.5ms\n",
      "Speed: 1.6ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 7.0ms\n",
      "Speed: 1.8ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 backpack, 1 skateboard, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 backpacks, 1 skateboard, 6.7ms\n",
      "Speed: 1.6ms preprocess, 6.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 2 backpacks, 1 skateboard, 8.3ms\n",
      "Speed: 1.7ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 backpacks, 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 backpack, 1 handbag, 1 skateboard, 7.3ms\n",
      "Speed: 2.7ms preprocess, 7.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 1 handbag, 7.9ms\n",
      "Speed: 1.8ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 3 backpacks, 1 skateboard, 7.0ms\n",
      "Speed: 2.1ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 backpacks, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 1 skateboard, 12.2ms\n",
      "Speed: 2.8ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 2 backpacks, 1 skateboard, 6.9ms\n",
      "Speed: 2.4ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 backpack, 1 skateboard, 6.8ms\n",
      "Speed: 1.8ms preprocess, 6.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 1 skateboard, 7.8ms\n",
      "Speed: 2.9ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 backpack, 1 skateboard, 7.4ms\n",
      "Speed: 1.9ms preprocess, 7.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 persons, 1 backpack, 2 skateboards, 7.1ms\n",
      "Speed: 1.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 1 backpack, 1 skateboard, 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 backpacks, 1 skateboard, 7.2ms\n",
      "Speed: 3.2ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 backpacks, 1 skateboard, 13.8ms\n",
      "Speed: 1.9ms preprocess, 13.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 backpacks, 1 skateboard, 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 backpacks, 1 skateboard, 6.9ms\n",
      "Speed: 1.8ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 backpacks, 1 skateboard, 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 2 backpacks, 9.4ms\n",
      "Speed: 1.8ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 backpacks, 1 handbag, 7.6ms\n",
      "Speed: 2.2ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 2 backpacks, 1 handbag, 7.5ms\n",
      "Speed: 1.9ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 persons, 2 backpacks, 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# Ensuring we have sourceVideo variable set if not then set a default value.\n",
    "if sourceVideo == \"\":\n",
    "    sourceVideo = \"https://download.microsoft.com/download/caaf80b6-2394-4fbc-8430-8b41a3206c64/people-are-pushing-carts-along.mp4\"\n",
    "\n",
    "# Running the inferencing.\n",
    "run_inference(\n",
    "    source=sourceVideo,\n",
    "    deviceType=\"CPU\",\n",
    "    objectToCount=objectToCount\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb75b97e",
   "metadata": {},
   "source": [
    "### Bonus activities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4070b004",
   "metadata": {},
   "source": [
    "#### 1. Adding/removing track lines for person counting\n",
    "\n",
    "In this bonus activity, we will change code to allow track lines to be visible in case we are tracking objects in motion.\n",
    "\n",
    "- To accomplish this, change the \"draw_tracks\" parameter in run_inference function to reflect if tracks are required or not.\n",
    "- Rerun the notebook after making change to test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d60493",
   "metadata": {},
   "source": [
    "#### 2. Change the dimenions of the bounding box\n",
    "\n",
    "In this bonus activity, we will change the code to draw the bounding box with different dimenions.\n",
    "\n",
    "- To accomplish this, change the run_inference function to change the line_points variable.\n",
    "- Example line_points = [(0, 600), (800, 600),(800, 0),(0,0),(0,600)] \n",
    "- Rerun the notebook after making change to test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
